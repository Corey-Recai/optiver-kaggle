{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7a93038-0144-43fb-be3e-399133f75e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a4b3553-e7d3-488c-86da-97576a96906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from os import walk\n",
    "from zipfile import ZipFile\n",
    "import re\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import sqlalchemy\n",
    "import pprint\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44f81b4c-3a90-4b31-a7d0-cf8b80745744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optiver-kaggle.env file already exists\n",
      "Please make sure that your file contains:\n",
      "\tKAGGLE_USERNAME=\"username\"\n",
      "\tKAGGLE_KEY=\"xxxxxxxxxxxxxx\"\n"
     ]
    }
   ],
   "source": [
    "env_file = \"optiver-kaggle.env\"\n",
    "env_user_message = 'Please make sure that your file contains:\\n\\tKAGGLE_USERNAME=\"username\"\\n\\tKAGGLE_KEY=\"xxxxxxxxxxxxxx\"'\n",
    "if os.path.isfile(env_file):\n",
    "    print(f\"{env_file} file already exists\")\n",
    "    print(env_user_message)\n",
    "else:\n",
    "    print(f\"creating {env_file} file\")\n",
    "    !touch optiver-kaggle.env\n",
    "    print(f\"Created {env_file}\")\n",
    "    print(env_user_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3594087a-9491-42d9-b5a9-c1ba34c25c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(env_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc7e14e0-18ce-45f1-a955-a49fb08f3578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_download(extraction_path):\n",
    "    file_name = \"optiver-realized-volatility-prediction.zip\"\n",
    "    !kaggle competitions download -c optiver-realized-volatility-prediction\n",
    "    with ZipFile(file_name, 'r') as zip:\n",
    "        print('Extracting all the files now...')\n",
    "        zip.extractall(extraction_path)\n",
    "        print('Done!')\n",
    "    !rm -rf optiver-realized-volatility-prediction.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac91cdc1-265d-4b55-810e-8a5f652779c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data directory already exists\n"
     ]
    }
   ],
   "source": [
    "data_path = \"./data\"\n",
    "download_message = \"Downloading data files...\"\n",
    "if os.path.isdir(data_path):\n",
    "    print(f\"{data_path} directory already exists\")\n",
    "    if len(os.listdir(data_path)) == 0:\n",
    "        print(f\"{data_path} directory is empty.\")\n",
    "        print(download_message)\n",
    "        source_download(data_path)\n",
    "else:\n",
    "    print(f\"Creating {data_path} directory...\")\n",
    "    !mkdir data\n",
    "    print(download_message)\n",
    "    source_download(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0dd3938-25d8-4619-9add-d6e8592e09e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = sqlalchemy.create_engine(\"sqlite:///OptiverKaggle.db\")\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "818aeb77-ee20-4dee-b751-080c85371c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2bd0518-6e10-4342-8acd-f07d4b715c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths(root_path):\n",
    "    paths = []\n",
    "    for (dirpath, dirnames, filenames) in walk(root_path):\n",
    "        if os.name == 'posix':\n",
    "            if \"/stock_id\" in dirpath:\n",
    "                paths.append(f\"{dirpath}/{filenames[0]}\")\n",
    "        if os.name == 'nt':\n",
    "            if \"\\stock_id\" in dirpath:\n",
    "                paths.append(f\"{dirpath}\\\\{filenames[0]}\")\n",
    "            \n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2259d91-133a-45cb-8c48-ca14d0d52593",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_names = [\"book_test\", \"book_train\", \"trade_test\", \"trade_train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39c26922-6a90-4f4e-b649-2456c52fe152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_id(path_substring):\n",
    "    if os.name == 'posix':\n",
    "        return re.sub('/[a-z0-9]*','', path_substring.replace('=','_'))\n",
    "    if os.name == 'nt':\n",
    "        return re.sub('\\\\\\\\[a-z0-9]*','', path_substring.replace('=','_'))\n",
    "\n",
    "def get_df_name(dirname, stock_id):\n",
    "    return f\"{dirname}_{stock_id}\"\n",
    "\n",
    "def load_df(file_path):\n",
    "    return pd.read_parquet(file_path, engine=\"pyarrow\")\n",
    "\n",
    "def read_data(paths):\n",
    "    df_names = []\n",
    "    for path in paths:\n",
    "        if data_names[0] in path:\n",
    "            stock_id = get_stock_id(path[25:38])\n",
    "            df_name = get_df_name(data_names[0], stock_id)\n",
    "            df_names.append(df_name)\n",
    "            g[df_name] = load_df(path)\n",
    "        elif data_names[1] in path:\n",
    "            stock_id = get_stock_id(path[26:38])\n",
    "            df_name = get_df_name(data_names[1], stock_id)\n",
    "            df_names.append(df_name)\n",
    "            g[df_name] = load_df(path)\n",
    "        elif data_names[2] in path:\n",
    "            stock_id = get_stock_id(path[26:38])\n",
    "            df_name = get_df_name(data_names[2], stock_id)\n",
    "            df_names.append(df_name)\n",
    "            g[df_name] = load_df(path)\n",
    "        elif data_names[3] in path:\n",
    "            stock_id = get_stock_id(path[27:40])\n",
    "            df_name = get_df_name(data_names[3], stock_id)\n",
    "            df_names.append(df_name)\n",
    "            g[df_name] = load_df(path)\n",
    "    return df_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "069b01bc-be2d-4659-9b97-415dd9a68fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df_name):\n",
    "     return g.get(df_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f336dd5-5fbc-49ce-b0fc-0868f8759e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_db(data_list):\n",
    "    for data in data_list:\n",
    "        if not engine.dialect.has_table(conn, data):\n",
    "            get_data(data).to_sql(data, engine, if_exists='fail')\n",
    "            print(f'{data} has been added to {conn.engine.url}')\n",
    "        else:\n",
    "            print(f'{data} already exists in {conn.engine.url}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0ddd589-f155-46ed-beb3-a1adab44f27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = get_paths(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a48ab704-36dc-4625-8ba4-659d7b10b3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = read_data(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "801832a5-4a7b-41e1-90cf-990c7d9a42f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To preview the data in the DataFrames\n",
    "# use the get_data() function to retive \n",
    "# the value from the global. Example below:\n",
    "\n",
    "    # get_data(data_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "852f0af9-ec35-434a-94d2-f5aabcf2e751",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed_db(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a678735-6e4e-4440-b498-f5d13745d5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns={}\n",
    "for i in range(len(data_list)):\n",
    "    signature = \", \".join(list(get_data(data_list[i]).columns))\n",
    "    if signature not in columns:\n",
    "        columns[signature] = 1\n",
    "    else:\n",
    "        columns[signature] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "345c5908-2683-4a66-a177-c88c0cea942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_columns = f\"stock_id, {list(columns.keys())[0]}\".split(\",\")\n",
    "trade_columns = f\"stock_id, {list(columns.keys())[1]}\".split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d77f533-fc5b-4e59-b2b8-c0eb65fbba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_csv():\n",
    "    for name in data_names:\n",
    "        if \"trade\" in name:\n",
    "            with open(f\"./data/{name}.csv\", \"w\") as csvfile:\n",
    "                writer = csv.writer(csvfile) \n",
    "                writer.writerow(trade_columns) \n",
    "        if \"book\" in name:\n",
    "            with open(f\"./data/{name}.csv\", \"w\") as csvfile: \n",
    "                writer = csv.writer(csvfile) \n",
    "                writer.writerow(book_columns) \n",
    "        \n",
    "    for data in data_list:\n",
    "        if data_names[0] in data:\n",
    "            get_data(data).insert(loc=0, column=\"stock_id\", value=data[19:])\n",
    "            get_data(data).to_csv(f\"./data/{data_names[0]}.csv\", mode=\"a\", header=False)\n",
    "        if data_names[1] in data:\n",
    "            get_data(data).insert(loc=0, column=\"stock_id\", value=data[20:])\n",
    "            get_data(data).to_csv(f\"./data/{data_names[1]}.csv\", mode=\"a\", header=False)\n",
    "        if data_names[2] in data:\n",
    "            get_data(data).insert(loc=0, column=\"stock_id\", value=data[20:])\n",
    "            get_data(data).to_csv(f\"./data/{data_names[2]}.csv\", mode=\"a\", header=False)\n",
    "        if data_names[3] in data:\n",
    "            get_data(data).insert(loc=0, column=\"stock_id\", value=data[21:])\n",
    "            get_data(data).to_csv(f\"./data/{data_names[3]}.csv\", mode=\"a\", header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33d42e82-e8d2-4310-b861-b5216a59301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3419044-d9d4-4b7f-8d7b-ef4e31245f82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
